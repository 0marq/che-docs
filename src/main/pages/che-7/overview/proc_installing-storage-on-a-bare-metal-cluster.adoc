// Module included in the following assemblies:
//
// installing-{prod-id-short}-with-kubespray

[id="installing-a-storage-on-bare-metal-cluster_{context}"]
= Installing a storage on a bare metal cluster

Deployments usually require storage in order to persist data since pods are designed to be ephemerals.

Kubernetes introduced several concepts around this:

* Persistant Volume `PV`: a declaration of an available volume
* Persistant Volume Claim `PVC`: a claim for Persistent Volume
* etc.

For more details, please refer to the official Kubernetes documentation about storage that covers `volumes`, `PV`, `PVC`, provisioning and much more.

In this article, you will use a `nfs` volume type for its simplicity, accessiblity between nodes and capability to be dynamically provisioned.

.Set up the NFS server

Based on the Vitux tutorial.

. Install NFS server
+
Just pick a machine on the same network as your cluster nodes (it can be one of them), and run:
+
----
sudo apt-get install -y nfs-kernel-server
----

. Choose export directory
+
Choose or create a directory and share it:
+
----
sudo mkdir -p /mnt/my-nfs
----
+
As we want all clients to have access, change its permissions
+
----
sudo chown nobody:nogroup /mnt/my-nfs
sudo chmod 777 /mnt/my-nfs
----

. Do the NFS export
+
----
echo "<mount-path> <subnet>(rw,sync,no_subtree_check)" | sudo tee /etc/exports
sudo exportfs -a
sudo systemctl restart nfs-kernel-server
----
+
[NOTE]
====
You have to replace <subnet> and <mount-path> with your `nfs` settings
====

.Define the StorageClass and the provisioner

Based on the Yolanda tutorial.
We will use an link:https://github.com/kubernetes-incubator/external-storage[external-storage] template.

. Set authorizations
+
----
kubectl apply -f https://raw.githubusercontent.com/kubernetes-incubator/external-storage/master/nfs-client/deploy/rbac.yaml
----

. Set StorageClass
+
----
cat << EOF | kubectl apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: managed-nfs-storage
  annotations: 
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: nfs-provisioner
parameters:
  archiveOnDelete: "false"
EOF
----
+
We declare the `StorageClass` as default one to automatically be selected by `PVC`s.

. Set provisioner
+
----
cat << EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-client-provisioner
  labels:
    app: nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: default
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: nfs-client-provisioner
  template:
    metadata:
      labels:
        app: nfs-client-provisioner
    spec:
      serviceAccountName: nfs-client-provisioner
      containers:
        - name: nfs-client-provisioner
          image: quay.io/external_storage/nfs-client-provisioner:latest
          volumeMounts:
            - name: nfs-client-root
              mountPath: /persistentvolumes
          env:
            - name: PROVISIONER_NAME
              value: nfs-provisioner
            - name: NFS_SERVER
              value: <nfs-server-ip>
            - name: NFS_PATH
              value: <mount-path>
      volumes:
        - name: nfs-client-root
          nfs:
            server: <nfs-server-ip>
            path: <mount-path>
EOF
----
+
[NOTE]
====
Don't forget to replace <nfs-server-ip> and <mount-path> with your custom `nfs` settings
====

.Check everything is OK

----
kubectl get deployments.apps,pods,sc -n default
----

You should see the `Deployment` of the provisioner, the corresponding `Pod` and also the `StorageClass` as default one.